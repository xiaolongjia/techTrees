https://www.jianshu.com/p/233b91d869f8

https://zhuanlan.zhihu.com/p/111844817

https://sparkbyexamples.com/pyspark-tutorial/
https://sparkbyexamples.com/pyspark-tutorial/#external-data-sources



Scala 2.11.8
jdk 1.8
python anaconda 3.7

========================================
1. jdk c:\java\
========================================

config JAVA_HOME
add %JAVA_HOME%\bin into PATH

========================================
2. Hadoop  (hadoop-3.1.4) 
========================================

config HADOOP_HOME C:\hadoop
add %HADOOP_HOME%\bin 
add %HADOOP_HOME%\sbin 
into PATH


https://www.apache.org/dist/hadoop/common/

3. winutils 3.2.0

https://github.com/cdarlint/winutils

copy all files under /bin/ to  C:\hadoop\bin
copy hadoop.dll to C:\windows\system32\

4. check 

hadoop -version 

5. config hadoop 

C:\hadoop\etc\hadoop\

core-site.xml

<configuration>
    <property>
      <name>hadoop.tmp.dir</name>
      <value>/C:/hadoop/data</value>
    </property>
    <property>
      <name>fs.defaultFS</name>
      <value>hdfs://localhost:7000</value>
    </property>
</configuration>

hadoop-env.cmd

set JAVA_HOME= %JAVA_HOME%


hdfs-site.xml

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/C:/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/C:/hadoop/data/datanode</value>
    </property>
</configuration>

mapred-site.xml

<configuration>
     <property>
      	  <name>mapreduce.framework.name</name>
     	    <value>yarn</value>
    </property>
</configuration>

yarn-site.xml

<configuration>
	 <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
	<property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hahoop.mapred.ShuffleHandler</value>
    </property>
</configuration>

6. init hdfs node 

hdfs namenode -format

7. start hadoop (run win terminal as administrator)

C:\hadoop\sbin

start-all.cmd

checking:  
http://localhost:8088/ # cluster 
http://localhost:9870/ # hdfs 

8. stop hadoop 

stop-all.cmd

========================================
9. spark 
========================================

https://archive.apache.org/dist/spark/

spark-3.1.1-bin-hadoop3.2

config SPARK_HOME=C:\spark\spark-3.1.1-bin-hadoop3.2
add %SPARK_HOME%\bin into PATH

check with:  spark-shell

mklink python3.exe python.exe

manage app execution alias 

========================================
10. PySpark 
========================================
Spark 3.1.1

cp C:\spark\spark-3.1.1-bin-hadoop3.2\python\lib\
py4j-0.10.4-src.zip
pyspark.zip

to 

C:\python38\Lib\site-packages or C:\Anaconda3\Lib\site-packages

and unzip them 

checking: 

import pyspark as ps

========================================
11. Kafka 
========================================

https://www.goavega.com/install-apache-kafka-on-windows/


# download kakka

https://kafka.apache.org/downloads
kafka_2.12-2.7.0 (Scala 2.12, Kafka 2.7)


#2.3.3对应spark2.3.3，2.11对应scala2.11
/usr/local/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1 03_DataStreaming.py


# create directories

C:\Kafka\data
C:\Kafka\data\kafka
C:\Kafka\data\zookeeper
C:\Kafka\logs

# set config files 

C:\Kafka\config\zookeeper.properties
dataDir=C:/Kafka/data/zookeeper

C:\Kafka\config\server.properties
log.dirs=C:/Kafka/data/kafka

#-----------------------
# run zookeeper
#-----------------------

cd C:\Kafka\bin\windows\
zookeeper-server-start.bat ../../config/zookeeper.properties

#-----------------------
# run kafka
#-----------------------
cd C:\Kafka\bin\windows\
kafka-server-start.bat  ../../config/server.properties

kafka commands:
# topics

kafka-topics.bat --zookeeper localhost:2181 --list

kafka-topics.bat --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic Hello-Kafka

kafka-topics.bat --zookeeper localhost:2181 --delete --topic Hello-Kafka


# show all messages 
kafka-topics.bat --list --zookeeper localhost:2181

# producer to send messages to a topic 

kafka-console-producer.bat --bootstrap-server localhost:9092 --topic Hello-Kafka

# consumer to receive messages 

kafka-console-consumer.bat --bootstrap-server localhost:9092 —topic Hello-Kafka --from-beginning

# python module 

pip install kafka-python

